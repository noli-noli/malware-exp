from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingClassifier
import numpy as np
import optuna
import os
import pandas as pd
import matplotlib.pyplot as plot

#勾配ブースティング木を使用した機械学習モデル

##### データセットの読込 #####
#データセットのパッチを指定
dataset = os.path.join("..","..","dataset","MalwareData.csv")
#データセットの読込
MalwareDataset = pd.read_csv(dataset,sep='|')
#MalwareDatasetからname,md5,legitimateを除外してXに格納する
X = MalwareDataset.drop(["Name","md5","legitimate"],axis="columns")
#legitimateをyに格納する
y = MalwareDataset["legitimate"]
#########


##### データセットの分割 #####
# データセットを訓練用とテスト用に分割
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, shuffle=True, random_state=101
    )
##########



# optunaの探索結果として得られたベストのパラメータを設定
model = GradientBoostingClassifier(
    max_depth = 3,
    max_features = "log2",
    learning_rate = 0.010015334131655331,
    criterion="squared_error"
    )

# モデルの訓練
model.fit(X_train, y_train)

# テスト用のデータを使用して予測
pred = model.predict(X_test)

# 予測結果とテスト用のデータを使って正解率と、混同行列を出力
print("Accuracy: {:.5f} %".format(100 * accuracy_score(y_test, pred)))
print(confusion_matrix(y_test, pred))


feat_importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=True)
feat_importances.plot(kind='barh',figsize=(20,10))
plot.savefig(f"GradientBoostingClassifier.png",dpi=200)