from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.metrics import accuracy_score 
from sklearn.model_selection import train_test_split
import numpy as np
import optuna
from sklearn.model_selection import cross_validate
import os
import pandas as pd
import matplotlib.pyplot as plot
from lightgbm import LGBMClassifier
from xgboost import XGBClassifier
import argparse

##### データセットの読込 #####
#データセットのパッチを指定
dataset = os.path.join("..","dataset","MalwareData.csv")
#データセットの読込
MalwareDataset = pd.read_csv(dataset,sep='|')
#MalwareDatasetからname,md5,legitimateを除外してXに格納する
X = MalwareDataset.drop(["Name","md5","legitimate"],axis="columns")
#legitimateをyに格納する
y = MalwareDataset["legitimate"]
#########


##### データセットの分割 #####
# データセットを訓練用とテスト用に分割
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, shuffle=True, random_state=101
    )
##########


##### ハイパーパラメータ探索用クラス #####
# RandomForestClassifierのハイパーパラメータ探索用のクラスを設定
class Objective_RF:
    def __init__(self, X, y):
        self.X = X
        self.y = y

    def __call__(self, trial):
        # Hyperparameter suggestions for optimization
        criterion = trial.suggest_categorical("criterion", ["gini", "entropy"])
        bootstrap = trial.suggest_categorical('bootstrap', [True, False])
        max_features = trial.suggest_categorical('max_features', ['sqrt','log2'])
        min_samples_split = trial.suggest_int('min_samples_split', 2, 5)
        min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)

        # Create RandomForestClassifier with suggested hyperparameters
        model = RandomForestClassifier(
            criterion=criterion,
            bootstrap=bootstrap,
            max_features=max_features,
            min_samples_split=min_samples_split,
            min_samples_leaf=min_samples_leaf
        )

        # Cross-validate the model
        scores = cross_validate(model, X=self.X, y=self.y, cv=5, n_jobs=-1)

        # Return the mean accuracy of the model across 5 folds
        return scores['test_score'].mean()
##########



##### 勾配ブースティング木のハイパーパラメータ探索用クラス #####
class Objective_GBC:
    def __init__(self, X, y):
        self.X = X
        self.y = y

    def __call__(self, trial):
        # 探索対象のパラメーターの指定
        max_depth=int(
            trial.suggest_loguniform("max_depth", 3, 10))
        max_features = trial.suggest_categorical(
            "max_features", ["log2", "sqrt"])
        learning_rate = float(trial.suggest_loguniform(
            "learning_rate", 0.03, 1))
        criterion =  trial.suggest_categorical(
            "criterion", ["friedman_mse",'squared_error'])

        # モデルの初期化
        model = GradientBoostingClassifier(
            max_depth = max_depth,
            max_features = max_features,
            learning_rate = learning_rate,
            criterion=criterion
            )
        
        scores = cross_validate(model,
                                X=self.X, y=self.y,
                                cv=5,
                                n_jobs=-1)
        return scores['test_score'].mean()
##########



##### AdaBoostのハイパーパラメータ探索用クラス #####
class Objective_AB:
    def __init__(self, X, y):
        self.X = X
        self.y = y

    def __call__(self, trial):
        # 探索対象のパラメーターの指定
        algorithm =  trial.suggest_categorical("algorithm", ["SAMME", "SAMME.R"])
        learning_rate = float(trial.suggest_loguniform("learning_rate", 0.01, 1))

        # モデルの初期化
        model = AdaBoostClassifier(
            algorithm = algorithm,
            learning_rate = learning_rate
            )
        
        scores = cross_validate(model,
                                X=self.X, y=self.y,
                                cv=5,
                                n_jobs=-1)
        return scores['test_score'].mean()
##########





##### XGBoostのハイパーパラメータ探索用クラス #####
class Objective_XB:
    def __init__(self, X, y):
        self.X = X
        self.y = y

    def __call__(self, trial):
        # 探索対象のパラメーターの指定
        booster =  trial.suggest_categorical("booster", ["gbtree"])
        max_depth=int(trial.suggest_loguniform("max_depth", 3, 10))
        learning_rate = float(trial.suggest_loguniform("learning_rate", 0.01, 1))

        # モデルの初期化
        model = XGBClassifier(
            booster = booster,
            max_depth = max_depth,
            learning_rate = learning_rate
            )
        
        scores = cross_validate(model,
                                X=self.X, y=self.y,
                                cv=5,
                                n_jobs=-1)
        return scores['test_score'].mean()
##########




##### LightGBMのハイパーパラメータ探索用クラス #####
class Objective_LGBM:
    def __init__(self, X, y):
        self.X = X
        self.y = y

    def __call__(self, trial):
        # 探索対象のパラメーターの指定
        boosting_type =  trial.suggest_categorical("boosting_type",  ['gbdt', 'dart', 'goss'])
        max_depth=int(trial.suggest_loguniform("max_depth", 3, 10))
        learning_rate = float(trial.suggest_loguniform("learning_rate", 0.01, 1))

        # モデルの初期化
        model = LGBMClassifier(
            boosting_type = boosting_type,
            max_depth = max_depth,
            learning_rate = learning_rate
            )
        
        scores = cross_validate(model,
                                X=self.X, y=self.y,
                                cv=5,
                                n_jobs=-1)
        return scores['test_score'].mean()
##########



#### 引数の設定 ####
parser = argparse.ArgumentParser(description="探索するモデルを指定")
parser.add_argument("model_class", help="Objective_RF, Objective_GBC, Objective_AB, Objective_XB, Objective_LGBM")
model_class = parser.parse_args()
if model_class.model_class == "Objective_RF":
    select_model = Objective_RF
elif model_class.model_class == "Objective_GBC":
    select_model = Objective_GBC
elif model_class.model_class == "Objective_AB":
    select_model = Objective_AB
elif model_class.model_class == "Objective_XB":
    select_model = Objective_XB
elif model_class.model_class == "Objective_LGBM":
    select_model = Objective_LGBM
else:
    print("モデルが見つかりません")
    exit()
####################

# 探索の対象クラスを設定
objective = select_model(X_train, y_train)
study = optuna.create_study()


# 最大で60分間探索を実行
study.optimize(objective, timeout=3600)


# 1回のみ探索
#study.optimize(objective, n_trials=1000)


# ベストのパラメータの出力
print('\nparams:', study.best_params)

