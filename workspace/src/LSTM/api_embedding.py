import os
import json
#os.environ['TF_CPP_MIN_LOG_LEVEL']='1'
import pandas as pd
import numpy as np
from keras.preprocessing.text import Tokenizer
from keras.preprocessing import sequence



from sklearn.model_selection import train_test_split

from keras.models import Sequential
from keras.layers import Dense, Embedding, LSTM
from keras.callbacks import EarlyStopping
import matplotlib.pyplot as plt
from sklearn.metrics import precision_score, recall_score, f1_score


import lstm_tensorflow

#探索するワードサイズ
max_words = 800
#API列のサイズ
max_len = 500


api_dataset = os.path.join("/workspace","dataset","mal-api-2019.txt")
label_dataset = os.path.join("/workspace","dataset","mal-label-2019.csv")

def Preprocessing():
    ##### データセットの読込 #####
    with open(api_dataset) as f:
        content = f.readlines()
    content = [x.strip() for x in content]
    data = pd.DataFrame()
    data['feature'] = content
    ############################


    ##### X軸データセットの前処理 #####
    X = data["feature"]
    tokenizer = Tokenizer(num_words=max_words)
    tokenizer.fit_on_texts(X)
    X = tokenizer.texts_to_sequences(X)
    X = sequence.pad_sequences(X, maxlen=max_len, truncating='post')
    print(tokenizer.word_index)
    #############################



    ##### Y軸データセットの前処理 #####
    with open(label_dataset) as f:
        label = f.readlines()
    label = [x.strip() for x in label]
    data["label"] = label
    y = data["label"].apply(lambda x: 1 if x == "Virus" else 0)
    print(y)
    #############################


    ##### データセットのスプリット #####
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)
    print(type(X_train))
    print(type(X_test))
    print(type(y_train))
    print(type(y_test))
    #############################

    np.savez('Virus.npz', X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)

def malware_model():
    model = Sequential()
    model.add(Embedding(max_words, 300, input_length=max_len))
    model.add(LSTM(32))
    model.add(Dense(1, activation='sigmoid'))
    return model

Preprocessing()

Processed_dataset =  os.path.join("/workspace","src","LSTM","Virus.npz")
loaded_data = np.load(Processed_dataset)
X_train = loaded_data['X_train']
X_test = loaded_data['X_test']
y_train = loaded_data['y_train']
y_test = loaded_data['y_test']


vocab_size = np.max(X_train) + 1
print(vocab_size)
#for i in y_train:
#    print(i)


custom_embedding = lstm_tensorflow.CustomEmbeddingLayer(300, 300)
embedded_X_train = custom_embedding.forward(X_train)
embedded_X_test = custom_embedding.forward(X_test)

tmp = lstm_tensorflow.LSTM_model(100,(500,300))
model = tmp.build_model()
model.summary()

#model = malware_model()
#print(model.summary())
#model.compile(
#    loss='binary_crossentropy',
#    optimizer='adam',metrics=['accuracy']
#    )
early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)
Custom_EarlyStopping = lstm_tensorflow.Custom_EarlyStopping(3)

    
history = model.fit(
    embedded_X_train,
    y_train, 
    batch_size=64, 
    epochs=30, 
    validation_data=(embedded_X_test, y_test), 
    verbose=1,
    callbacks=[early_stopping]
    )

#lossとaccuracyの算出
loss,accuracy = model.evaluate(embedded_X_test,y_test)
#モデル評価
predicted = model.predict(embedded_X_test)

y_pred= (predicted > 0.5).astype(int)
# y_testも0と1に変換
y_test = (y_test > 0.5).astype(int)

precision = precision_score(y_test,y_pred)
recall = recall_score(y_test,y_pred)
f1 = f1_score(y_test,y_pred)

# 結果の出力
print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1 Score: {f1:.4f}')
print(f'Accuracy: {accuracy:.4f}')

plt.plot(y_train, label='True')
plt.plot(predicted,label='Predicted')
plt.legend()
plt.savefig(f"LSTM.png",dpi=200)

